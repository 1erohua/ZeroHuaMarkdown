心血来潮，想写一波细颗粒度的数据结构，优先使用互斥锁，看情况使用原子变量。如果允许我就都实现。实现包括：**队列、栈、链表、列。**

**关于多线程的数据结构，必须谨记一点：写的操作既要考虑多线程的同时写，更要考虑多线程的同时读写。（即别忘了读的部分）**

# 互斥锁队列——基于std::queue
~~队列是先进先出的结构，**存储共享指针**。~~
~~我没有打算做那种只有一个互斥锁锁住整个队列的。因为队列是头弹出尾插入，实际上这两个操作是可分的。如果不重写queue而是使用`std::queue`，那就需要两个互斥量`pop_mtx`和`push_mtx`。当然，这里的实现确实存在数据竞争问题。~

如果是基于std::queue，会出现一个问题：由于颗粒度不够细，分别对pop和push进行互斥锁，很可能因为扩容导致std::queue内部指针变化，引起我们操作的问题。
下面是原来的做法：
```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <assert.h>
#include <queue>

template<typename T>
class LockQueue{
private:
    // 两个互斥量分别控制头尾（插弹）操作
    std::mutex push_mtx;
    std::mutex pop_mtx;
    std::condition_variable cv;

    using Ptr = std::shared_ptr<T>;
    std::queue<Ptr> _queue;

public:
    LockQueue() = default;
    LockQueue(const LockQueue&) = delete;
    LockQueue& operator=(const LockQueue&) = delete;

    // 像之前一样，双版本的push
    void push(const T& value){
	    Ptr ptr = std::make_shared<T>(value);
        {
        std::lock_guard<std::mutex> lock(push_mtx);
        _queue.push(ptr);
        }
        cv.notify_one();
    }

    void push(T&& value){
        Ptr ptr = std::make_shared<T>(std::move(value));
        {
        std::lock_guard<std::mutex> lock(push_mtx);
        _queue.push(ptr);
        }
        cv.notify_one();
    }

    // 再次修正，只要保证全局锁顺序一致，双锁就不会造成死锁（沟槽的重排序别害我就行）
    Ptr try_pop(){
        Ptr temp_ptr;
        {
        std::unique_lock<std::mutex> lock1(pop_mtx);

        if(_queue.empty()){ // 
            std::unique_lock<std::mutex> lock2(push_mtx);
            if(_queue.empty()){
                return Ptr();
            }
            lock2.unlock(); // 执行到这里, 已经不需要再锁着lock2了
        }
        temp_ptr = _queue.front();
        _queue.pop();
        }

        return temp_ptr;
    }

    bool try_pop(T &data){
        std::unique_lock<std::mutex> lock1(pop_mtx);

        // 这里是双重锁定判空操作
        if(_queue.empty()){ // 
	        std::unique_lock<std::mutex> lock2(push_mtx);
	        if(_queue.empty()){
		        return false;
	        }
            return false;
            lock2.unlock(); // 同上, 也不需要再锁着push操作了
        }
        data = std::move(*(_queue.front())); // 如果这里抛出异常，这不必进行弹出操作，不影响栈内数据
        _queue.pop();

        return true;
    }

    Ptr wait_and_pop(){
        std::unique_lock<std::mutex> lock1(pop_mtx);
        cv.wait(lock1, [&]{
            // 后面才想到能在lambda进行开锁
            std::unique_lock<std::mutex> lock2(push_mtx); // 只要保证两个锁，锁定的顺序一致，就没有问题
            return !_queue.empty(); // 再锁再判断
        }); // lock2出了这个作用域就会自动解锁，因此不用管它

        Ptr temp = _queue.front();
        _queue.pop();
        return temp;
    }

    void wait_and_pop(T& data){
        std::unique_lock<std::mutex> lock1(pop_mtx);
        cv.wait(lock1,[&]{
            std::unique_lock<std::mutex> lock2(push_mtx); // 同上
            return !_queue.empty();
        }); // 同上，不必手动管理lock2

        data = std::move(*(_queue.front()));
        _queue.pop();
    }

    bool empty(){
        std::unique_lock<std::mutex> lock1(pop_mtx);
        if(_queue.empty()){
            std::unique_lock<std::mutex> lock2(push_mtx);
            if(_queue.empty()){
                return true;
            }
            lock2.unlock();
        } // 与try_pop如出一辙的弹出锁顺序，这样应该就能保证全局锁顺序一致

        return false;
    }

};

}
```
让AI写一个复杂样例之后确实出现了报错，并且再用该样例测试下面的链表实现（稍微加个函数改点不关键的东西），也能完美通过，这是AI的解释：

原版 `try_pop` 的锁设计如下：


```cpp
bool try_pop(T &data) {
    std::unique_lock<std::mutex> lock1(pop_mtx); // 仅锁定 pop_mtx
    if (_queue.empty()) { 
        std::unique_lock<std::mutex> lock2(push_mtx); // 再次检查时锁定 push_mtx
        if (_queue.empty()) return false;
        lock2.unlock(); // 解锁 push_mtx
    }
    data = std::move(*_queue.front()); // 此时 push_mtx 未锁定！
    _queue.pop();
    return true;
}
```

#### 问题场景：

1. **线程A**调用 `try_pop`，通过 `pop_mtx` 锁定，发现队列非空。
    
2. **线程B**调用 `push`，通过 `push_mtx` 锁定，向队列添加元素。
    
    - 此时队列可能触发内部内存重新分配（如动态扩容）。
        
3. **线程A**继续执行 `data = std::move(*_queue.front())`，但此时队列的底层内存可能已被线程B修改。
    
    - **后果**：访问无效指针，导致段错误。
因而建议还是实现单互斥锁吧
```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <assert.h>
#include <queue>

template<typename T>
class LockQueue{
private:
    // 两个互斥量分别控制头尾（插弹）操作
    std::mutex mtx;
    std::condition_variable cv;

    using Ptr = std::shared_ptr<T>;
    std::queue<Ptr> _queue;

public:
    LockQueue() = default;
    LockQueue(const LockQueue&) = delete;
    LockQueue& operator=(const LockQueue&) = delete;

    // 像之前一样，双版本的push
    void push(const T& value){
	    Ptr ptr = std::make_shared<T>(value);
        {
        std::lock_guard<std::mutex> lock(mtx);
        _queue.push(ptr);
        }
        cv.notify_one();
    }

    void push(T&& value){
        Ptr ptr = std::make_shared<T>(std::move(value));
        {
        std::lock_guard<std::mutex> lock(mtx);
        _queue.push(ptr);
        }
        cv.notify_one();
    }

    Ptr try_pop(){
        Ptr temp_ptr;
        {
        std::unique_lock<std::mutex> lock1(mtx);

        if(_queue.empty()){ // 
            return Ptr();
        }
        temp_ptr = _queue.front();
        _queue.pop();
        }

        return temp_ptr;
    }

    bool try_pop(T &data){
        std::unique_lock<std::mutex> lock1(mtx);

        // 这里是双重锁定判空操作
        if(_queue.empty()){ // 
		    return false;
        }
        data = std::move(*(_queue.front())); // 如果这里抛出异常，这不必进行弹出操作，不影响栈内数据
        _queue.pop();

        return true;
    }

    Ptr wait_and_pop(){
        std::unique_lock<std::mutex> lock1(mtx);
        cv.wait(lock1, [&]{
            return !_queue.empty(); // 再锁再判断
        }); 

        Ptr temp = _queue.front();
        _queue.pop();
        return temp;
    }

    void wait_and_pop(T& data){
        std::unique_lock<std::mutex> lock1(mtx);
        cv.wait(lock1,[&]{
            return !_queue.empty();
        }); 

        data = std::move(*(_queue.front()));
        _queue.pop();
    }

    bool empty(){
        std::unique_lock<std::mutex> lock1(mtx);
        if(_queue.empty()){
            return true;
        } 

        return false;
    }

};

```


# 互斥锁队列——链表实现
忆往昔——环形队列的特点，或者说队列的特点，头指针在队列非空的时候永远指向有数据的位置，尾指针永远指向没有数据的位置。**因而引入虚节点的概念，尾指针永远指向虚节点，虚节点永远是队列最后一个节点。初始时，头指针与尾指针共同指向虚节点。**
最后写完才发现，和上一个章节差不多。(完全拿来练习指针了)

```cpp

#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <queue>

template<typename T>
class ThreadSafeQueue{
private:
    struct Node
    {
        std::shared_ptr<T> data_ptr;
        std::unique_ptr<Node> next;
    };
    
    std::unique_ptr<Node> head;
    Node* tail; // 初始时与head指向同一个节点，因此不能是unique_ptr; 并且在后续，最后一个有效数据块的next也是指向虚数据块

    std::mutex head_mtx;
    std::mutex tail_mtx;

    std::condition_variable cv;

public:
    ThreadSafeQueue():head(std::make_unique<Node>()),tail(head.get()){}
    // 删除一切拷贝构造
    ThreadSafeQueue(const ThreadSafeQueue&) = delete;
    ThreadSafeQueue& operator=(const ThreadSafeQueue&) = delete;

    void push(T&& data){
        // 创建数据指针和节点
        auto data_ptr = std::make_shared<T>(std::move(data));
        std::unique_ptr<Node> new_node = std::make_unique<Node>();
        {
            std::lock_guard<std::mutex> lock(tail_mtx);
            tail->data_ptr = data_ptr;
            tail->next = std::move(new_node);
            tail = (tail->next).get();
        }
        cv.notify_one();
    }

    void push(const T& data){
        // 创建数据指针和节点
        auto data_ptr = std::make_shared<t>(data);
        std::unique_ptr<Node> new_node = std::make_unique<Node>();
        {
            std::lock_guard<std::mutex> lock(tail_mtx);
            tail->data_ptr = data_ptr;
            tail->next = std::move(new_node);
            tail = (tail->next).get();
        }
        cv.notify_one();
    }

    bool try_pop(T& data){
        {
            // GetTail已经进行对tail_mtx的锁定了，且全局锁定顺序都是一致的
            std::lock_guard<std::mutex> lock(head_mtx);
            if(head.get() == GetTail()){
                return false;
            }

            data = std::move(*(head->data_ptr));
            head = head->next;
        }
        return true;
    }

    void wait_and_pop(T& data){
        {
            std::unique_lock<std::mutex> lock(head_mtx);
            cv.wait(lock,[this]{
                // 在内部再进行锁定，赌重排序不可能会将这个先上锁，并且按照代码顺序来说全局上锁顺序一致
                std::lock_guard<std::mutex> lock(tail_mtx);
                return !(head.get() == tail);
            });

            data = std::move(*(head->data_ptr));
            head = head->next;
        }
    }
    // 下面两个就是对上面的拙劣模仿了
    std::shared_ptr<T> try_pop(){
        std::shared_ptr<T> temp_ptr;
        {
            // GetTail已经进行对tail_mtx的锁定了，且全局锁定顺序都是一致的
            std::lock_guard<std::mutex> lock(head_mtx);
            if(head.get() == GetTail().get()){
                return nullptr;
            }

            temp_ptr = std::move(head->data_ptr);
            head = head->next;
        }
        return temp_ptr;
    }

    std::shared_ptr<T> wait_and_pop(){
        std::shared_ptr<T> temp_ptr;
        {
            std::unique_lock<std::mutex> lock(head_mtx);
            cv.wait(lock,[this]{
                // 在内部再进行锁定，赌重排序不可能会将这个先上锁，并且按照代码顺序来说全局上锁顺序一致
                std::lock_guard<std::mutex> lock(tail_mtx);
                return !(head.get() == tail());
            });

            temp_ptr = std::move(head->data_ptr);
            head = head->next;
        }
        return temp_ptr;
    }


    std::unique_ptr<Node> GetTail(){
        std::lock_guard<std::mutex> lock(tail_mtx);
        return tail;
    }

};

```


# 无锁队列
这一段并不是我写的：
基于Michael-Scott无锁算法：

```cpp
#include <atomic>
#include <memory>

template<typename T>
class LockFreeQueue {
private:
    struct Node {
        std::shared_ptr<T> data;
        std::atomic<Node*> next;

        Node() : next(nullptr) {}
        explicit Node(T value) : data(std::make_shared<T>(value)), next(nullptr) {}
    };

    std::atomic<Node*> head;
    std::atomic<Node*> tail;

public:
    LockFreeQueue() {
        Node* dummy = new Node();
        head.store(dummy);
        tail.store(dummy);
    }

    ~LockFreeQueue() {
        while (Node* old_head = head.load()) {
            head.store(old_head->next);
            delete old_head;
        }
    }

    void enqueue(T value) {
        Node* new_node = new Node(value);
        Node* current_tail = nullptr;
        Node* next = nullptr;

        while (true) {
            // 看完之后会发现，tail是最后移动的，
            // 操作的顺序：
            // 将当前节点的next连接到新节点
            // 将tail指向新节点
            current_tail = tail.load(std::memory_order_acquire);
            next = current_tail->next.load(std::memory_order_acquire);
            // 问1：如果tail在这里被改了，那么就不会执行下面if块内的内容，而是再度更新

            if (current_tail == tail.load(std::memory_order_relaxed)) {
                // 问2：如果tail在这里被修改，则会去执行else的内容, 被修改后next!=nullptr
                if (next == nullptr) {
                    // 问3：如果tail在这里被修改, 则next必然不等于current_tail->next, 因为next是最初的next，即应该为nullptr(前提是前面都没有修改next，在这里修改了next)
                    if (current_tail->next.compare_exchange_weak( // 修改成功则代表修改过程中，current_tail->next和当时的next值一样，没有修改tail
                        next, new_node,
                        std::memory_order_release,
                        std::memory_order_relaxed)) {
                        break;
                    }
                } else { // 协助别的线程修改
                // 这里协助的意思是，当next不为空时，并且current_tail等于tail，认为tail没有来得及更新, 则协助别的线程进行更新
                // 如果出现问2的情况，则不会发生修改, 即若出现current_tail不等于tail的情况，则不会触发修改
                    tail.compare_exchange_weak(
                        current_tail, next,
                        std::memory_order_release,
                        std::memory_order_relaxed);
                }
            }
        }

        // 一旦跳出这个循环，即代表新节点已经被成功连接
        tail.compare_exchange_weak(
            current_tail, new_node,
            std::memory_order_release,
            std::memory_order_relaxed);
    }

    std::shared_ptr<T> dequeue() {
        Node* current_head = nullptr;
        Node* current_tail = nullptr;
        Node* next = nullptr;
        std::shared_ptr<T> res;

        while (true) {
            current_head = head.load(std::memory_order_acquire);
            current_tail = tail.load(std::memory_order_acquire);
            next = current_head->next.load(std::memory_order_acquire);

            if (current_head == head.load(std::memory_order_relaxed)) {
                if (current_head == current_tail) {
                    if (next == nullptr) return nullptr; // 队列空
                    
                    // 队列非空，但是tail指针还没更新
                    // 手动更新
                    tail.compare_exchange_weak(
                        current_tail, next,
                        std::memory_order_release,
                        std::memory_order_relaxed);
                } else {
                    res = next->data;
                    // head指针只需要往前移就行了，不像tail涉及到要建立指针的连接
                    if (head.compare_exchange_weak(
                        current_head, next,
                        std::memory_order_release,
                        std::memory_order_relaxed)) {
                        // 头节点更新成功
                        break;
                    }
                }
            }
        }
        delete current_head; // 简单示例，实际需要安全内存回收
        // 这里的delete应该是唯一的问题了。
        return res;
    }
}
```
在`enqueue`函数的最后，使用`tail.compare_exchange_weak(current_tail, new_node)`确实可能会因为其他线程已经更新了`tail`而导致当前线程的CAS操作失败。然而，这种失败是设计预期的，并且不会影响队列的正确性。以下是关键点：

1. **并发更新的处理**：
   - 当当前线程成功将新节点链接到`current_tail->next`后，可能有其他线程观察到`tail->next`不为空（即新节点已被链接），并协助将`tail`移动到新节点。
   - 如果其他线程已经更新了`tail`，当前线程的CAS会失败，但此时`tail`已经被正确设置到新节点，因此无需进一步操作。

2. **最终一致性**：
   - 无论由当前线程还是其他线程完成`tail`的更新，最终`tail`都会指向正确的新节点。
   - 最后的CAS是一个“尽力而为”的操作，目的是在可能的情况下直接完成`tail`的移动，否则依赖其他线程的协助。

3. **无阻塞保证**：
   - 即使当前线程的CAS失败，队列仍保持一致性，不会导致数据丢失或结构破坏。
   - 这种设计避免了线程在更新`tail`时无限制重试，提高了并发性能。

因此，`tail.compare_exchange_weak`的失败是允许的，且不会影响队列的正确性。这是无锁算法中常见的“协作”模式，通过多个线程共同维护数据结构的一致性。

# 线程池
